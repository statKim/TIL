{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import lightgbm as lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gini index 계산하는 함수\n",
    "def Gini(y_true, y_pred):\n",
    "    # 정답과 예측값의 개수가 동일한지 확인한다\n",
    "    assert y_true.shape == y_pred.shape\n",
    "    n_samples = y_true.shape[0]\n",
    "\n",
    "    # 예측값(y_pred)를 오름차순으로 정렬한다\n",
    "    arr = np.array([y_true, y_pred]).transpose()\n",
    "    true_order = arr[arr[:, 0].argsort()][::-1, 0]\n",
    "    pred_order = arr[arr[:, 1].argsort()][::-1, 0]\n",
    "\n",
    "    # Lorenz curves를 계산한다\n",
    "    L_true = np.cumsum(true_order) * 1. / np.sum(true_order)\n",
    "    L_pred = np.cumsum(pred_order) * 1. / np.sum(pred_order)\n",
    "    L_ones = np.linspace(1 / n_samples, 1, n_samples)\n",
    "\n",
    "    # Gini 계수를 계산한다\n",
    "    G_true = np.sum(L_ones - L_true)\n",
    "    G_pred = np.sum(L_ones - L_pred)\n",
    "\n",
    "    # Gini 계수를 정규화한다\n",
    "    return G_pred * 1. / G_true\n",
    "\n",
    "# LightGBM 모델 학습 과정에서 평가 함수로 사용한다\n",
    "def evalerror(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'gini', Gini(labels, preds), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련/테스트 데이터를 읽어온다\n",
    "train = pd.read_csv(\"../../data/train.csv\")\n",
    "train_label = train['target']\n",
    "train_id = train['id']\n",
    "del train['target'], train['id']\n",
    "\n",
    "test = pd.read_csv(\"../../data/test.csv\")\n",
    "test_id = test['id']\n",
    "del test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파생 변수 01 : 결측값을 의미하는 “-1”의 개수를 센다(각 행 별 결측치 개수)\n",
    "train['missing'] = (train==-1).sum(axis=1).astype(float)\n",
    "test['missing'] = (test==-1).sum(axis=1).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파생 변수 02 : 이진 변수의 합\n",
    "bin_features = [c for c in train.columns if 'bin' in c]\n",
    "train['bin_sum'] = train[bin_features].sum(axis=1)\n",
    "test['bin_sum'] = test[bin_features].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파생 변수 03 : 단일변수 타겟 비율 분석으로 선정한 변수를 기반으로 Target Encoding을 수행한다. Target Encoding은 교차 검증 과정에서 진행한다.\n",
    "features = ['ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin', 'ps_ind_09_bin', 'ps_ind_12_bin', 'ps_ind_16_bin', 'ps_ind_17_bin', 'ps_ind_18_bin', 'ps_ind_04_cat', 'ps_ind_05_cat', 'ps_car_01_cat', 'ps_car_02_cat', 'ps_car_03_cat', 'ps_car_04_cat', 'ps_car_06_cat', 'ps_car_07_cat', 'ps_car_08_cat', 'ps_car_09_cat', 'ps_car_11_cat', 'ps_ind_01', 'ps_ind_03', 'ps_ind_15', 'ps_car_11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM 모델의 설정값이다.\n",
    "# parmaeter 설명(참고) : https://lightgbm.readthedocs.io/en/latest/Parameters.html\n",
    "num_boost_round = 10000\n",
    "params = { # Core Parameters\n",
    "          \"objective\": \"binary\",  # binary : logistic regression\n",
    "          \"boosting_type\": \"gbdt\", # gradient boosting decision tree(default)\n",
    "          \"learning_rate\": 0.1, # shirinkage rate\n",
    "          \"num_leaves\": 15, # 노드 최대 개수\n",
    "           # Learning Control Parameters\n",
    "          \"max_bin\": 256,\n",
    "          \"feature_fraction\": 0.6,\n",
    "          \"verbosity\": 0,\n",
    "          \"drop_rate\": 0.1,\n",
    "          \"is_unbalance\": False,\n",
    "          \"max_drop\": 50,\n",
    "          \"min_child_samples\": 10,\n",
    "          \"min_child_weight\": 150,\n",
    "          \"min_split_gain\": 0,\n",
    "          \"subsample\": 0.9,\n",
    "          \"seed\": 2018\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\safe_driver\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Anaconda3\\envs\\safe_driver\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's gini: 0.289057\n",
      "[200]\tvalid_0's gini: 0.289507\n",
      "Early stopping, best iteration is:\n",
      "[128]\tvalid_0's gini: 0.290886\n",
      "0.290885768895\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's gini: 0.263882\n",
      "[200]\tvalid_0's gini: 0.265789\n",
      "Early stopping, best iteration is:\n",
      "[163]\tvalid_0's gini: 0.266903\n",
      "0.266902573663\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's gini: 0.276838\n",
      "[200]\tvalid_0's gini: 0.278797\n",
      "Early stopping, best iteration is:\n",
      "[192]\tvalid_0's gini: 0.27924\n",
      "0.279239808758\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's gini: 0.28051\n",
      "[200]\tvalid_0's gini: 0.280624\n",
      "Early stopping, best iteration is:\n",
      "[147]\tvalid_0's gini: 0.281718\n",
      "0.281718470101\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's gini: 0.286562\n",
      "[200]\tvalid_0's gini: 0.284692\n",
      "Early stopping, best iteration is:\n",
      "[117]\tvalid_0's gini: 0.286767\n",
      "0.286767320145\n"
     ]
    }
   ],
   "source": [
    "# Stratified 5-Fold 내부 교차 검증을 준비한다\n",
    "NFOLDS = 5\n",
    "kfold = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=218) # random_state : seed 지정\n",
    "kf = kfold.split(train, train_label)\n",
    "\n",
    "cv_train = np.zeros(len(train_label))\n",
    "cv_pred = np.zeros(len(test_id))    \n",
    "best_trees = []\n",
    "fold_scores = []\n",
    "\n",
    "for i, (train_fold, validate) in enumerate(kf): # train_fold, validate : 각 fold에 포함되는 데이터들의 index\n",
    "    # 훈련/검증 데이터를 분리한다 (training set을 fold로 구분하여 validation set 생성)\n",
    "    X_train, X_validate, label_train, label_validate = train.iloc[train_fold, :], train.iloc[validate, :], train_label[train_fold], train_label[validate]\n",
    "    \n",
    "    # target encoding 피쳐 엔지니어링을 수행한다\n",
    "    for feature in features:\n",
    "        # 훈련 데이터에서 feature 고유값별 타겟 변수의 평균을 구한다\n",
    "        # 즉, Kth fold를 제외한 데이터들의 feature 열과 y값을 transpose한 후 feature로 groupby해서 mean 구해라!!\n",
    "        map_dic = pd.DataFrame([X_train[feature], label_train]).T.groupby(feature).agg('mean')\n",
    "        map_dic = map_dic.to_dict()['target']  # dataframe을 dict로 바꾸고 거기서 'target'변수만 가져와라!!\n",
    "        # 훈련/검증/테스트 데이터에 평균값을 매핑한다  - .get(key값, deault키값):key값이 있으면 가져오고 없으면 default키 값을 가져온다\n",
    "        X_train[feature + '_target_enc'] = X_train[feature].apply(lambda x: map_dic.get(x, 0))\n",
    "        X_validate[feature + '_target_enc'] = X_validate[feature].apply(lambda x: map_dic.get(x, 0))\n",
    "        test[feature + '_target_enc'] = test[feature].apply(lambda x: map_dic.get(x, 0))\n",
    "\n",
    "    dtrain = lgbm.Dataset(X_train, label_train)\n",
    "    dvalid = lgbm.Dataset(X_validate, label_validate, reference=dtrain)\n",
    "    \n",
    "    # 훈련 데이터를 학습하고, evalerror() 함수를 통해 검증 데이터에 대한 정규화 Gini 계수 점수를 기준으로 최적의 트리 개수를 찾는다.\n",
    "    bst = lgbm.train(params, dtrain, num_boost_round, valid_sets=dvalid, feval=evalerror, verbose_eval=100, early_stopping_rounds=100)\n",
    "    best_trees.append(bst.best_iteration)\n",
    "    \n",
    "    # 테스트 데이터에 대한 예측값을 cv_pred에 더한다.\n",
    "    cv_pred += bst.predict(test, num_iteration=bst.best_iteration) # 최적 tree 개수를 사용한 모델로 predict\n",
    "    cv_train[validate] += bst.predict(X_validate) # validate(index)에 해당하는 cv_train 각 index에 predict값을 갹각 더함(원래는 0임)\n",
    "\n",
    "    # 검증 데이터에 대한 평가 점수를 출력한다.\n",
    "    score = Gini(label_validate, cv_train[validate])\n",
    "    print(score)\n",
    "    fold_scores.append(score)\n",
    "\n",
    "cv_pred /= NFOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score:\n",
      "0.280973903402\n",
      "[0.29088576889478723, 0.26690257366267167, 0.27923980875765608, 0.28171847010071399, 0.28676732014459044]\n",
      "[128, 163, 192, 147, 117] 149.4\n"
     ]
    }
   ],
   "source": [
    "# 시드값별로 교차 검증 점수를 출력한다.\n",
    "print(\"cv score:\")\n",
    "print(Gini(train_label, cv_train))\n",
    "print(fold_scores)\n",
    "print(best_trees, np.mean(best_trees))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터에 대한 결과물을 저장한다.\n",
    "pd.DataFrame({'id': test_id, 'target': cv_pred}).to_csv('../model/lgbm_baseline.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "safe_driver",
   "language": "python",
   "name": "safe_driver"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
