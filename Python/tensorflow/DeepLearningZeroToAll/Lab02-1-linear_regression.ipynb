{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2 Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab02-1-linear_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(777)  # seed 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "x_train = [1, 2, 3]\n",
    "y_train = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regerssion 결과는 W = 1, b = 0 이라는 것을 알 수 있음\n",
    "### but tensorflow로 training 시켜서 해보기!!\n",
    "### W와 b는 어떻게 달라질까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.Variable() : tensorflow가 사용하는 변수(trainable variable)\n",
    "# tf.random_normal([1]) : normal dist에서 1개의 난수 생성\n",
    "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression model\n",
    "hypothesis = x_train * W + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost/loss function (MSE)\n",
    "# tf.square() : 제곱해주는 tf 함수\n",
    "# tf.reduce_mean() : mean 구해주는 tf 함수\n",
    "# hypothesis(y_hat), y_train(true value)\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GradientDescent\n",
    "# Minimize\n",
    "# learning rate=0.01로 training 시킴 => gradient descent로 인해 조금씩 true에 가까워짐\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session 객체 생성(tf graph 객체 생성)\n",
    "sess = tf.Session()\n",
    "# 모든 tf variavle 초기화\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.82329 [ 2.12867713] [-0.85235667]\n",
      "20 0.190351 [ 1.53392804] [-1.05059612]\n",
      "40 0.151357 [ 1.45725465] [-1.02391243]\n",
      "60 0.13727 [ 1.43085384] [-0.97795272]\n",
      "80 0.124669 [ 1.41013741] [-0.93219817]\n",
      "100 0.113226 [ 1.39081788] [-0.88840771]\n",
      "120 0.102834 [ 1.37244678] [-0.84665769]\n",
      "140 0.0933952 [ 1.3549428] [-0.80686814]\n",
      "160 0.084823 [ 1.33826172] [-0.76894832]\n",
      "180 0.0770376 [ 1.32236469] [-0.73281056]\n",
      "200 0.0699668 [ 1.30721486] [-0.69837117]\n",
      "220 0.063545 [ 1.29277682] [-0.66555047]\n",
      "240 0.0577126 [ 1.27901745] [-0.63427216]\n",
      "260 0.0524155 [ 1.26590466] [-0.6044637]\n",
      "280 0.0476046 [ 1.25340807] [-0.57605624]\n",
      "300 0.0432353 [ 1.24149871] [-0.54898357]\n",
      "320 0.0392669 [ 1.23014927] [-0.52318329]\n",
      "340 0.0356628 [ 1.21933293] [-0.49859545]\n",
      "360 0.0323896 [ 1.20902514] [-0.47516325]\n",
      "380 0.0294167 [ 1.19920158] [-0.45283225]\n",
      "400 0.0267167 [ 1.18983996] [-0.4315508]\n",
      "420 0.0242646 [ 1.18091822] [-0.41126958]\n",
      "440 0.0220375 [ 1.17241573] [-0.39194146]\n",
      "460 0.0200148 [ 1.16431284] [-0.37352163]\n",
      "480 0.0181777 [ 1.1565907] [-0.35596743]\n",
      "500 0.0165093 [ 1.14923155] [-0.33923826]\n",
      "520 0.014994 [ 1.14221787] [-0.3232953]\n",
      "540 0.0136178 [ 1.13553429] [-0.30810148]\n",
      "560 0.0123679 [ 1.1291647] [-0.29362184]\n",
      "580 0.0112327 [ 1.12309468] [-0.27982271]\n",
      "600 0.0102017 [ 1.11730957] [-0.26667204]\n",
      "620 0.00926539 [ 1.11179638] [-0.25413945]\n",
      "640 0.00841497 [ 1.10654235] [-0.24219586]\n",
      "660 0.00764263 [ 1.10153544] [-0.23081362]\n",
      "680 0.00694115 [ 1.09676349] [-0.21996623]\n",
      "700 0.00630405 [ 1.0922159] [-0.20962858]\n",
      "720 0.00572545 [ 1.08788216] [-0.19977672]\n",
      "740 0.00519995 [ 1.08375216] [-0.19038804]\n",
      "760 0.00472267 [ 1.07981586] [-0.18144041]\n",
      "780 0.0042892 [ 1.07606494] [-0.17291337]\n",
      "800 0.00389553 [ 1.07249022] [-0.16478711]\n",
      "820 0.00353798 [ 1.06908345] [-0.1570428]\n",
      "840 0.00321324 [ 1.06583679] [-0.14966238]\n",
      "860 0.00291833 [ 1.06274283] [-0.14262886]\n",
      "880 0.00265048 [ 1.05979395] [-0.13592596]\n",
      "900 0.00240721 [ 1.05698395] [-0.12953788]\n",
      "920 0.00218626 [ 1.05430591] [-0.12345006]\n",
      "940 0.0019856 [ 1.05175376] [-0.11764836]\n",
      "960 0.00180335 [ 1.04932141] [-0.11211928]\n",
      "980 0.00163783 [ 1.04700351] [-0.10685005]\n",
      "1000 0.0014875 [ 1.04479456] [-0.10182849]\n",
      "1020 0.00135098 [ 1.04268944] [-0.09704296]\n",
      "1040 0.00122698 [ 1.04068327] [-0.09248237]\n",
      "1060 0.00111436 [ 1.03877103] [-0.08813594]\n",
      "1080 0.00101208 [ 1.03694892] [-0.08399385]\n",
      "1100 0.000919187 [ 1.03521252] [-0.08004645]\n",
      "1120 0.000834821 [ 1.03355765] [-0.07628451]\n",
      "1140 0.000758196 [ 1.03198063] [-0.07269943]\n",
      "1160 0.000688605 [ 1.03047752] [-0.06928282]\n",
      "1180 0.000625402 [ 1.02904522] [-0.06602671]\n",
      "1200 0.000567998 [ 1.02768016] [-0.06292368]\n",
      "1220 0.000515865 [ 1.02637935] [-0.05996648]\n",
      "1240 0.000468516 [ 1.02513957] [-0.05714824]\n",
      "1260 0.000425516 [ 1.02395821] [-0.0544625]\n",
      "1280 0.00038646 [ 1.02283216] [-0.05190301]\n",
      "1300 0.00035099 [ 1.02175927] [-0.04946378]\n",
      "1320 0.000318777 [ 1.02073693] [-0.04713925]\n",
      "1340 0.000289521 [ 1.01976228] [-0.0449241]\n",
      "1360 0.000262945 [ 1.01883328] [-0.04281275]\n",
      "1380 0.00023881 [ 1.01794815] [-0.04080062]\n",
      "1400 0.000216891 [ 1.01710474] [-0.03888312]\n",
      "1420 0.000196985 [ 1.01630092] [-0.03705578]\n",
      "1440 0.000178903 [ 1.01553476] [-0.03531429]\n",
      "1460 0.000162482 [ 1.01480472] [-0.03365463]\n",
      "1480 0.000147569 [ 1.0141089] [-0.03207294]\n",
      "1500 0.000134025 [ 1.01344585] [-0.03056567]\n",
      "1520 0.000121723 [ 1.01281393] [-0.02912918]\n",
      "1540 0.000110551 [ 1.0122118] [-0.0277602]\n",
      "1560 0.000100404 [ 1.01163793] [-0.02645557]\n",
      "1580 9.11895e-05 [ 1.01109099] [-0.02521228]\n",
      "1600 8.28196e-05 [ 1.01056981] [-0.02402747]\n",
      "1620 7.52188e-05 [ 1.01007283] [-0.02289824]\n",
      "1640 6.83137e-05 [ 1.00959957] [-0.02182201]\n",
      "1660 6.2043e-05 [ 1.00914836] [-0.02079643]\n",
      "1680 5.63493e-05 [ 1.00871849] [-0.01981908]\n",
      "1700 5.11766e-05 [ 1.00830877] [-0.01888768]\n",
      "1720 4.64789e-05 [ 1.00791824] [-0.01800001]\n",
      "1740 4.22143e-05 [ 1.00754607] [-0.01715406]\n",
      "1760 3.83389e-05 [ 1.00719154] [-0.01634789]\n",
      "1780 3.48197e-05 [ 1.00685346] [-0.01557961]\n",
      "1800 3.16242e-05 [ 1.00653136] [-0.01484741]\n",
      "1820 2.87213e-05 [ 1.00622439] [-0.0141496]\n",
      "1840 2.60857e-05 [ 1.00593197] [-0.01348464]\n",
      "1860 2.36911e-05 [ 1.00565314] [-0.01285094]\n",
      "1880 2.15168e-05 [ 1.00538754] [-0.012247]\n",
      "1900 1.95421e-05 [ 1.00513422] [-0.01167146]\n",
      "1920 1.77484e-05 [ 1.00489295] [-0.01112291]\n",
      "1940 1.61197e-05 [ 1.00466311] [-0.01060018]\n",
      "1960 1.46397e-05 [ 1.004444] [-0.01010205]\n",
      "1980 1.32962e-05 [ 1.00423515] [-0.00962736]\n",
      "2000 1.20761e-05 [ 1.00403607] [-0.00917497]\n"
     ]
    }
   ],
   "source": [
    "# Fit\n",
    "# 2001번 최적화 시킴!!!\n",
    "for step in range(2001):\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0:  # 다 뽑으면 너무 많으니까 몇개만 뽑기 위해서\n",
    "        # step(몇 번째인지?), cost(mse), W(weight), b(bias)\n",
    "        print(step, sess.run(cost), sess.run(W), sess.run(b))\n",
    "        \n",
    "# Learns best fit W:[ 1.],  b:[ 0.]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
