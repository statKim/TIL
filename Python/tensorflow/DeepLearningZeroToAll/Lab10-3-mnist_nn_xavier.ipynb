{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 10 MNIST and Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab10-3-mnist_nn_xavier\n",
    "### - activation fn : ReLU\n",
    "### - Xavier : weight의 initial value 정하는 방법\n",
    "### - Accuracy = 0.9822 => 초기값 정하는 방법을 달리 함으로써 accuracy가 급격히 좋아짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(777)  # reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-a47c5bb27b44>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights & bias for nn layers\n",
    "# weights의 initial value를 정하는 방법으로 Xavier 사용(이전에는 normal dist에서 랜덤하게 뽑았었음)\n",
    "# http://stackoverflow.com/questions/33640581/how-to-do-xavier-initialization-on-tensorflow\n",
    "W1 = tf.get_variable(\"W1\", shape=[784, 256],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([256]))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = tf.get_variable(\"W2\", shape=[256, 256],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([256]))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "W3 = tf.get_variable(\"W3\", shape=[256, 10],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([10]))\n",
    "hypothesis = tf.matmul(L2, W3) + b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-81776f19df50>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define cost/loss & optimizer (using AdamOptimizer)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session 생성 및 변수 initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.300939396\n",
      "Epoch: 0002 cost = 0.113667043\n",
      "Epoch: 0003 cost = 0.073191098\n",
      "Epoch: 0004 cost = 0.052514119\n",
      "Epoch: 0005 cost = 0.038712961\n",
      "Epoch: 0006 cost = 0.029251834\n",
      "Epoch: 0007 cost = 0.024998846\n",
      "Epoch: 0008 cost = 0.020756620\n",
      "Epoch: 0009 cost = 0.016729372\n",
      "Epoch: 0010 cost = 0.014673262\n",
      "Epoch: 0011 cost = 0.012288880\n",
      "Epoch: 0012 cost = 0.010326613\n",
      "Epoch: 0013 cost = 0.009648957\n",
      "Epoch: 0014 cost = 0.010352560\n",
      "Epoch: 0015 cost = 0.010277308\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9822\n"
     ]
    }
   ],
   "source": [
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  [9]\n",
      "Prediction:  [9]\n"
     ]
    }
   ],
   "source": [
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwg8E9f+S6vXUwb/iswAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21c3c766ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\nEpoch: 0001 cost = 0.301498963\\nEpoch: 0002 cost = 0.107252513\\nEpoch: 0003 cost = 0.064888892\\nEpoch: 0004 cost = 0.044463030\\nEpoch: 0005 cost = 0.029951642\\nEpoch: 0006 cost = 0.020663404\\nEpoch: 0007 cost = 0.015853033\\nEpoch: 0008 cost = 0.011764387\\nEpoch: 0009 cost = 0.008598264\\nEpoch: 0010 cost = 0.007383116\\nEpoch: 0011 cost = 0.006839140\\nEpoch: 0012 cost = 0.004672963\\nEpoch: 0013 cost = 0.003979437\\nEpoch: 0014 cost = 0.002714260\\nEpoch: 0015 cost = 0.004707661\\nLearning Finished!\\nAccuracy: 0.9783\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(mnist.test.images[r:r + 1].\n",
    "          reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()\n",
    "\n",
    "'''\n",
    "Epoch: 0001 cost = 0.301498963\n",
    "Epoch: 0002 cost = 0.107252513\n",
    "Epoch: 0003 cost = 0.064888892\n",
    "Epoch: 0004 cost = 0.044463030\n",
    "Epoch: 0005 cost = 0.029951642\n",
    "Epoch: 0006 cost = 0.020663404\n",
    "Epoch: 0007 cost = 0.015853033\n",
    "Epoch: 0008 cost = 0.011764387\n",
    "Epoch: 0009 cost = 0.008598264\n",
    "Epoch: 0010 cost = 0.007383116\n",
    "Epoch: 0011 cost = 0.006839140\n",
    "Epoch: 0012 cost = 0.004672963\n",
    "Epoch: 0013 cost = 0.003979437\n",
    "Epoch: 0014 cost = 0.002714260\n",
    "Epoch: 0015 cost = 0.004707661\n",
    "Learning Finished!\n",
    "Accuracy: 0.9783\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
