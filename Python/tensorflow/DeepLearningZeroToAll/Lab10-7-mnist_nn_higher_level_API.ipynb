{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 10 MNIST and Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab10-7-mnist_nn_higher_level_API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import fully_connected, batch_norm, dropout\n",
    "from tensorflow.contrib.framework import arg_scope\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(777)  # reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-a47c5bb27b44>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "learning_rate = 0.01  # we can use large learning rate using Batch Normalization\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "keep_prob = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "train_mode = tf.placeholder(tf.bool, name='train_mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer output size\n",
    "hidden_output_size = 512\n",
    "final_output_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xavier_init = tf.contrib.layers.xavier_initializer()\n",
    "bn_params = {\n",
    "    'is_training': train_mode,\n",
    "    'decay': 0.9,\n",
    "    'updates_collections': None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can build short code using 'arg_scope' to avoid duplicate code\n",
    "# same function with different arguments\n",
    "with arg_scope([fully_connected],\n",
    "               activation_fn=tf.nn.relu,\n",
    "               weights_initializer=xavier_init,\n",
    "               biases_initializer=None,\n",
    "               normalizer_fn=batch_norm,\n",
    "               normalizer_params=bn_params\n",
    "               ):\n",
    "    hidden_layer1 = fully_connected(X, hidden_output_size, scope=\"h1\")\n",
    "    h1_drop = dropout(hidden_layer1, keep_prob, is_training=train_mode)\n",
    "    hidden_layer2 = fully_connected(h1_drop, hidden_output_size, scope=\"h2\")\n",
    "    h2_drop = dropout(hidden_layer2, keep_prob, is_training=train_mode)\n",
    "    hidden_layer3 = fully_connected(h2_drop, hidden_output_size, scope=\"h3\")\n",
    "    h3_drop = dropout(hidden_layer3, keep_prob, is_training=train_mode)\n",
    "    hidden_layer4 = fully_connected(h3_drop, hidden_output_size, scope=\"h4\")\n",
    "    h4_drop = dropout(hidden_layer4, keep_prob, is_training=train_mode)\n",
    "    hypothesis = fully_connected(h4_drop, final_output_size, activation_fn=None, scope=\"hypothesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-f02e71557745>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:    1] cost = 0.382780868\n",
      "[Epoch:    2] cost = 0.330968508\n",
      "[Epoch:    3] cost = 0.32185967\n",
      "[Epoch:    4] cost = 0.315274022\n",
      "[Epoch:    5] cost = 0.311545199\n",
      "[Epoch:    6] cost = 0.310111493\n",
      "[Epoch:    7] cost = 0.307930431\n",
      "[Epoch:    8] cost = 0.307182975\n",
      "[Epoch:    9] cost = 0.305391376\n",
      "[Epoch:   10] cost = 0.304477239\n",
      "[Epoch:   11] cost = 0.303453268\n",
      "[Epoch:   12] cost = 0.301850721\n",
      "[Epoch:   13] cost = 0.301658836\n",
      "[Epoch:   14] cost = 0.301292971\n",
      "[Epoch:   15] cost = 0.302490956\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict_train = {X: batch_xs, Y: batch_ys, train_mode: True}\n",
    "        feed_dict_cost = {X: batch_xs, Y: batch_ys, train_mode: False}\n",
    "        opt = sess.run(optimizer, feed_dict=feed_dict_train)\n",
    "        c = sess.run(cost, feed_dict=feed_dict_cost)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print(\"[Epoch: {:>4}] cost = {:>.9}\".format(epoch + 1, avg_cost))\n",
    "    #print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9844\n"
     ]
    }
   ],
   "source": [
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels, train_mode: False}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  [3]\n",
      "Prediction:  [3]\n"
     ]
    }
   ],
   "source": [
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1], train_mode: False}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n508CkAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b2007f7860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\n[Epoch:    1] cost = 0.519417209\\n[Epoch:    2] cost = 0.432551052\\n[Epoch:    3] cost = 0.404978843\\n[Epoch:    4] cost = 0.392039919\\n[Epoch:    5] cost = 0.382165317\\n[Epoch:    6] cost = 0.377987834\\n[Epoch:    7] cost = 0.372577601\\n[Epoch:    8] cost = 0.367208552\\n[Epoch:    9] cost = 0.365525589\\n[Epoch:   10] cost = 0.361964276\\n[Epoch:   11] cost = 0.359540287\\n[Epoch:   12] cost = 0.356423751\\n[Epoch:   13] cost = 0.354478216\\n[Epoch:   14] cost = 0.353212552\\n[Epoch:   15] cost = 0.35230893\\nLearning Finished!\\nAccuracy: 0.9826\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(mnist.test.images[r:r + 1].\n",
    "          reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()\n",
    "\n",
    "'''\n",
    "[Epoch:    1] cost = 0.519417209\n",
    "[Epoch:    2] cost = 0.432551052\n",
    "[Epoch:    3] cost = 0.404978843\n",
    "[Epoch:    4] cost = 0.392039919\n",
    "[Epoch:    5] cost = 0.382165317\n",
    "[Epoch:    6] cost = 0.377987834\n",
    "[Epoch:    7] cost = 0.372577601\n",
    "[Epoch:    8] cost = 0.367208552\n",
    "[Epoch:    9] cost = 0.365525589\n",
    "[Epoch:   10] cost = 0.361964276\n",
    "[Epoch:   11] cost = 0.359540287\n",
    "[Epoch:   12] cost = 0.356423751\n",
    "[Epoch:   13] cost = 0.354478216\n",
    "[Epoch:   14] cost = 0.353212552\n",
    "[Epoch:   15] cost = 0.35230893\n",
    "Learning Finished!\n",
    "Accuracy: 0.9826\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
