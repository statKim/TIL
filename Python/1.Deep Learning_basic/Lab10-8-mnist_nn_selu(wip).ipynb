{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 10 MNIST and Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab10-8-mnist_nn_selu(wip)\n",
    "- SELU implementation from https://github.com/bioinf-jku/SNNs/blob/master/selu.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "# -*- coding: utf-8 -*-\n",
    "'''\n",
    "Tensorflow Implementation of the Scaled ELU function and Dropout\n",
    "'''\n",
    "import numbers\n",
    "from tensorflow.contrib import layers\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.framework import tensor_shape\n",
    "from tensorflow.python.framework import tensor_util\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import random_ops\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.layers import utils\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(777)  # reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selu(x):\n",
    "    with ops.name_scope('elu') as scope:\n",
    "        alpha = 1.6732632423543772848170429916717\n",
    "        scale = 1.0507009873554804934193349852946\n",
    "        return scale*tf.where(x>=0.0, x, alpha*tf.nn.elu(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout_selu(x, keep_prob, alpha= -1.7580993408473766, fixedPointMean=0.0, fixedPointVar=1.0,\n",
    "                 noise_shape=None, seed=None, name=None, training=False):\n",
    "    \"\"\"Dropout to a value with rescaling.\"\"\"\n",
    "\n",
    "    def dropout_selu_impl(x, rate, alpha, noise_shape, seed, name):\n",
    "        keep_prob = 1.0 - rate\n",
    "        x = ops.convert_to_tensor(x, name=\"x\")\n",
    "        if isinstance(keep_prob, numbers.Real) and not 0 < keep_prob <= 1:\n",
    "            raise ValueError(\"keep_prob must be a scalar tensor or a float in the \"\n",
    "                                             \"range (0, 1], got %g\" % keep_prob)\n",
    "        keep_prob = ops.convert_to_tensor(keep_prob, dtype=x.dtype, name=\"keep_prob\")\n",
    "        keep_prob.get_shape().assert_is_compatible_with(tensor_shape.scalar())\n",
    "\n",
    "        alpha = ops.convert_to_tensor(alpha, dtype=x.dtype, name=\"alpha\")\n",
    "        keep_prob.get_shape().assert_is_compatible_with(tensor_shape.scalar())\n",
    "\n",
    "        if tensor_util.constant_value(keep_prob) == 1:\n",
    "            return x\n",
    "\n",
    "        noise_shape = noise_shape if noise_shape is not None else array_ops.shape(x)\n",
    "        random_tensor = keep_prob\n",
    "        random_tensor += random_ops.random_uniform(noise_shape, seed=seed, dtype=x.dtype)\n",
    "        binary_tensor = math_ops.floor(random_tensor)\n",
    "        ret = x * binary_tensor + alpha * (1-binary_tensor)\n",
    "\n",
    "        a = tf.sqrt(fixedPointVar / (keep_prob *((1-keep_prob) * tf.pow(alpha-fixedPointMean,2) + fixedPointVar)))\n",
    "\n",
    "        b = fixedPointMean - a * (keep_prob * fixedPointMean + (1 - keep_prob) * alpha)\n",
    "        ret = a * ret + b\n",
    "        ret.set_shape(x.get_shape())\n",
    "        return ret\n",
    "\n",
    "    with ops.name_scope(name, \"dropout\", [x]) as name:\n",
    "        return utils.smart_cond(training,\n",
    "                                lambda: dropout_selu_impl(x, keep_prob, alpha, noise_shape, seed, name),\n",
    "                                lambda: array_ops.identity(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-a47c5bb27b44>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 50\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropout (keep_prob) rate  0.7 on training, but should be 1 for testing\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights & bias for nn layers\n",
    "# http://stackoverflow.com/questions/33640581/how-to-do-xavier-initialization-on-tensorflow\n",
    "W1 = tf.get_variable(\"W1\", shape=[784, 512],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([512]))\n",
    "L1 = selu(tf.matmul(X, W1) + b1)\n",
    "L1 = dropout_selu(L1, keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = tf.get_variable(\"W2\", shape=[512, 512],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([512]))\n",
    "L2 = selu(tf.matmul(L1, W2) + b2)\n",
    "L2 = dropout_selu(L2, keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "W3 = tf.get_variable(\"W3\", shape=[512, 512],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([512]))\n",
    "L3 = selu(tf.matmul(L2, W3) + b3)\n",
    "L3 = dropout_selu(L3, keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "W4 = tf.get_variable(\"W4\", shape=[512, 512],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([512]))\n",
    "L4 = selu(tf.matmul(L3, W4) + b4)\n",
    "L4 = dropout_selu(L4, keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "W5 = tf.get_variable(\"W5\", shape=[512, 10],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "hypothesis = tf.matmul(L4, W5) + b5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-f02e71557745>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.525002178\n",
      "Epoch: 0002 cost = 0.161724900\n",
      "Epoch: 0003 cost = 0.125785579\n",
      "Epoch: 0004 cost = 0.108473961\n",
      "Epoch: 0005 cost = 0.094301452\n",
      "Epoch: 0006 cost = 0.090414509\n",
      "Epoch: 0007 cost = 0.080968445\n",
      "Epoch: 0008 cost = 0.081822040\n",
      "Epoch: 0009 cost = 0.078143769\n",
      "Epoch: 0010 cost = 0.070925551\n",
      "Epoch: 0011 cost = 0.061887159\n",
      "Epoch: 0012 cost = 0.067059740\n",
      "Epoch: 0013 cost = 0.056846072\n",
      "Epoch: 0014 cost = 0.056757542\n",
      "Epoch: 0015 cost = 0.051696500\n",
      "Epoch: 0016 cost = 0.048612948\n",
      "Epoch: 0017 cost = 0.043807761\n",
      "Epoch: 0018 cost = 0.047413503\n",
      "Epoch: 0019 cost = 0.054793650\n",
      "Epoch: 0020 cost = 0.043326182\n",
      "Epoch: 0021 cost = 0.041824071\n",
      "Epoch: 0022 cost = 0.043296074\n",
      "Epoch: 0023 cost = 0.044776860\n",
      "Epoch: 0024 cost = 0.029144197\n",
      "Epoch: 0025 cost = 0.035353001\n",
      "Epoch: 0026 cost = 0.048023093\n",
      "Epoch: 0027 cost = 0.028468076\n",
      "Epoch: 0028 cost = 0.042459968\n",
      "Epoch: 0029 cost = 0.058238270\n",
      "Epoch: 0030 cost = 0.031389067\n",
      "Epoch: 0031 cost = 0.022616670\n",
      "Epoch: 0032 cost = 0.025290699\n",
      "Epoch: 0033 cost = 0.030275834\n",
      "Epoch: 0034 cost = 0.049641470\n",
      "Epoch: 0035 cost = 0.031101960\n",
      "Epoch: 0036 cost = 0.029032887\n",
      "Epoch: 0037 cost = 0.027515099\n",
      "Epoch: 0038 cost = 0.033813630\n",
      "Epoch: 0039 cost = 0.021072055\n",
      "Epoch: 0040 cost = 0.032573817\n",
      "Epoch: 0041 cost = 0.033442625\n",
      "Epoch: 0042 cost = 0.021338611\n",
      "Epoch: 0043 cost = 0.032114372\n",
      "Epoch: 0044 cost = 0.035640072\n",
      "Epoch: 0045 cost = 0.030606819\n",
      "Epoch: 0046 cost = 0.030882951\n",
      "Epoch: 0047 cost = 0.033779118\n",
      "Epoch: 0048 cost = 0.021378192\n",
      "Epoch: 0049 cost = 0.022382120\n",
      "Epoch: 0050 cost = 0.022646739\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9831\n"
     ]
    }
   ],
   "source": [
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  [1]\n",
      "Prediction:  [1]\n"
     ]
    }
   ],
   "source": [
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1], keep_prob: 1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDyT1f1VqV6HxN6ZTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f2f3774438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\nEpoch: 0001 cost = 0.447322626\\nEpoch: 0002 cost = 0.157285590\\nEpoch: 0003 cost = 0.121884535\\nEpoch: 0004 cost = 0.098128681\\nEpoch: 0005 cost = 0.082901778\\nEpoch: 0006 cost = 0.075337573\\nEpoch: 0007 cost = 0.069752543\\nEpoch: 0008 cost = 0.060884363\\nEpoch: 0009 cost = 0.055276413\\nEpoch: 0010 cost = 0.054631256\\nEpoch: 0011 cost = 0.049675195\\nEpoch: 0012 cost = 0.049125314\\nEpoch: 0013 cost = 0.047231930\\nEpoch: 0014 cost = 0.041290121\\nEpoch: 0015 cost = 0.043621063\\nLearning Finished!\\nAccuracy: 0.9804\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(mnist.test.images[r:r + 1].\n",
    "          reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()\n",
    "\n",
    "'''\n",
    "Epoch: 0001 cost = 0.447322626\n",
    "Epoch: 0002 cost = 0.157285590\n",
    "Epoch: 0003 cost = 0.121884535\n",
    "Epoch: 0004 cost = 0.098128681\n",
    "Epoch: 0005 cost = 0.082901778\n",
    "Epoch: 0006 cost = 0.075337573\n",
    "Epoch: 0007 cost = 0.069752543\n",
    "Epoch: 0008 cost = 0.060884363\n",
    "Epoch: 0009 cost = 0.055276413\n",
    "Epoch: 0010 cost = 0.054631256\n",
    "Epoch: 0011 cost = 0.049675195\n",
    "Epoch: 0012 cost = 0.049125314\n",
    "Epoch: 0013 cost = 0.047231930\n",
    "Epoch: 0014 cost = 0.041290121\n",
    "Epoch: 0015 cost = 0.043621063\n",
    "Learning Finished!\n",
    "Accuracy: 0.9804\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
